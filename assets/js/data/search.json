[ { "title": "Hash Tables - Data Structures", "url": "/posts/hash-tables/", "categories": "Software Engineering, Data structures", "tags": "software engineering, data structures, caching", "date": "2023-12-19 00:00:00 +0300", "snippet": "TLDR; A hash table is a data structure that manages a collection of key-value pairs, they are widely used in DB indexing and caching. Hash tables support operations such as insertion, deletion, and lookup(search), with the requirement that keys must be unique. In the implementation of hash tables, an array A of size m is utilized, where m &amp;gt;= n. Each value x is placed inside a bucket at an array index determined by the hash function h(x), with the constraint that h(x) &amp;lt; m.In software engineering or computing, a hash table is a data structure which impelements a dictionary, you might ask what a dictionary is, simply put, a dictionary is another data structure that stores a collection of key-value pairs, some migth refer to it as a map or an associative array though the term dictionary is commonly accepted.Why Hash Tables?Good question, it‚Äôs very common to deal with related data when it comes to computing, for that, we use arrays. An array is a data structure used to store and organize data in a way that allows for efficient and random access, it consists of a collection of elements/items, each identified by an index. These elements are stored in contiguous memory locations and can be accessed directly by their index. The index is typically an integer that represents the position of an element in the array. You can think of an array as a bookshelf that has a fixed size, say 100 shelves (array size), each shelf contains something of sometype, it can be another shelf or just one item like a spoon for example.Now, consider a simple one-dimensional array of names [anna, lucas and ali], to find a name in this array, you can implement a bruteforce approach where you iterate through the array till you find the one you are looking for, this is technically refered to as linear search, the array [anna, lucas and ali] is relatively small but for a big array, it could take a considerable amount of time to find a name, now suppose you knew the position of the name in the array, it would take you less time to retrieve said name, regardless of the size of the array or the position of the name, but how do you know which position in the array contains the value you are looking for?, that‚Äôs the catch!, you do so by calculating the position depending on the value itself, this introduces relatedness between an element and it‚Äôs position in the array(the index) and that‚Äôs the gist of hash tables. By using this technique, they reduce the average time complexity from O(n)/linear time to O(1)/constant time üéâComponents Array of Buckets: Buckets, also known as slots or bins are containers within the array that make up the hash table. Each bucket holds one or more key-value pairs that share the same index, as determined by the hash function. Hash function: This is an integral part of hash tables, it‚Äôs a one-way mathematical function that computes the appropriate bucket index to store the key-pairs. In an ideal world, hash functions should be‚Ä¶ easy to compute. deterministic, meaning for a given key, it always produces the same output. # An example of a hash function that # illustrates their deterministic nature echo &quot;hello&quot; | sha256sum # always produces this hash code -&amp;gt; # 5891b5b522d5df086d0ff0b110fbd9d21bb4fc7163af34d08286a2e846f6be03 able avoid (atleast most of the times) collisions. This happens when a hash function computes the same index i when given different keys. Collisions are inevitable in hash tables due to the finite range of space and an infinite number of possible keys. You might ask why we are not using the keys themselves as identifiers for their assciated values instead of passing them through a hash function, This helps in keeping all the ops on the data structure with an average time complexity of O(1), Otherwise you‚Äôd have to keep a sorted list of keys, which is much slower to store and retrieve mappings from, or worse, have an unsorted array that results in an average time complexity of O(n). There are several strategies to handle collisions and two common approaches are: Separate Chaining: In this approach, each bucket in the hash table contains a linked list (or another data structure) that holds all key-value pairs that hash to the same index. When a collision occurs, the new key-value pair is simply added to the existing list at that index. Open Addressing: In open addressing, when a collision occurs, the algorithm searches for the next available (unoccupied) slot in the array. This can involve various techniques such as linear probing (checking the next slot), quadratic probing, or double hashing. Using a Hash TableHash tables are already implemented and optimized for you in many programming languages, In Typescript/Javascript for example, you can use a hash table by instanciating the built in Map class.const map1 = new Map();map1.set(&quot;a&quot;, 1);map1.set(&quot;b&quot;, 2);map1.set(&quot;c&quot;, 3);console.log(map1.get(&quot;a&quot;));// Expected output: 1map1.set(&quot;a&quot;, 97);console.log(map1.get(&quot;a&quot;));// Expected output: 97console.log(map1.size);// Expected output: 3map1.delete(&quot;b&quot;);console.log(map1.size);// Expected output: 2Summary Hash tables are used to index large amounts of data, whether be it for caching or DB indexing The position/address/index of each key is calculated using the key itself by employing a hashing technique which should ideally minimize collisions. Should they occur, they are resolved by employing various techniques such as open addressing or separate chaining. Operations done on a hash table have an average time complexity of O(1)/constant time, meaning, regardless of the size of the store, it will take the same amount of time to either insert, search or delete an element/value, this degrades from O(1) to O(n) if there are many collisions. The performance of a hash table is directly proportional to the chosen hash function‚Äôs ability to disperse the indices. However, construction of such a hash function is practically impossible, that being so, implementations depend on case-specific collision resolution techniques in achieving higher performance.Recommended Resources Use Maps more and Objects less - Steve from (Builder.io)I hope you enjoyed reading this.Take good care ü§ù" }, { "title": "I&#39;m Back üòÉ", "url": "/posts/im-back/", "categories": "Life, Career", "tags": "", "date": "2023-12-18 00:00:00 +0300", "snippet": "Hi there üëã, i‚Äôm back.It‚Äôs been a while and i hope you are doing well.I took some time off due to career changes, moving from network engineering to software development, it‚Äôs been quite a journey.Am glad i did network engineering before transitioning to development. What‚Äôs particularly satisfying for me is how seamlessly my infrastructure and IT experience from networking transitioned into the world of development. Join me as i continue exploring and stay tuned for more.Take good care ü§ù." }, { "title": "OSPF - Open Shortest Path First", "url": "/posts/ospf/", "categories": "Network Engineering, Dynamic Routing", "tags": "cisco, ccna, ospf, routing, networking", "date": "2022-05-06 00:00:00 +0300", "snippet": "OSPF is an open standard, it is a linkstate routing protocol that dynamically chooses the routes based on the cost of the links that the packet will traverse compared to distance vector routing protocols like RIP (Routing information protocol) that choose a path depending on the number of hops a packet has to take in order to reach the destination Network, it is probably one of the most desployed IGP (interior gateway protocol) in existence today, you see it in environments such as data centres, service providers and enterprise. This is because of its robustness and how much you can do with the protocol. In this post, we‚Äôll take a look at how OSPF operates and an overview of its basic concepts.OSPF ConceptsHello messagesThis is a protocol used to discover OSPF neighbors and confirm reachability, this is also used in the election of a DR.OSPF path costOSPF makes its routing decisions based on the cost associated with the link speed, the cost is a function of that link speed and is calculated by Reference Bandwidth / Interface Bandwidth. A Gigabit link 1000mbps for example is a cost of 1 if the Reference Bandwidth is 1000 mbps, ahundred megabit link 100 mbps is a cost of 10. Routers have become much faster and the default reference bandwidth of 1000 mbps isn‚Äôt enough, this reference bandwidth can be changed to fit your environment by executing Remember to change the reference bandwidth on all routers running OSPF.enableconfigure terminalrouter ospf &amp;lt;PROCESS NUMBER&amp;gt;auto-cost reference-bandwidth &amp;lt;BANDWIDTH IN mbps&amp;gt; You can override the OSPF cost calculation for interfaces by configuring the cost directly on the interface of your choice.enableconfigure terminalinterface &amp;lt;INTERFACE&amp;gt;ip ospf cost &amp;lt;1-65535&amp;gt;OSPF Router ID (RID)An OSPF RID is used to distinguish between routers in an OSPF area. When an OSPF process is brought up, the router checks to see if a RID has been configured, if none are configured, it falls back to the 2nd option which is the loopback address, if many loopback addresses exist on the router, it uses the loopback address with the highest IP address. for example, loopback0 with 5.5.5.5/32 will be chosen over loopback1 with 2.2.2.2/32. if both of these aren‚Äôt configured, OSPF will use the highest IP address on any active interface as RID of that OSPF process, assigning a RID while an OSPF process is running will result in that new RID to take effect immediately, assigning a higher IP to some active interfaces or creating new loopbacks will not be used on a running OSPF process unless it‚Äôs terminated or the router is restarted. You can obtain the router ID of an active OSPF process by executingenableshow ip ospfNeighborsOSPF Neighbors are routers that reside on the same network segment/subnet, they exchange Hello messages using the multicast address of 224.0.0.5 for ipv4 and FF02::5 for ipv6, OSPF uses multicast and unicast, rather than broadcast, for sending messages. Neighbors are not yet adjacent to each other but they know of their presence. To find the list of OSPF neighbors, executeenableshow ip ospf neighborsAdjacenciesThe prerequisite of a successful adjacency formation is that both routers need to be neighbors first. You can‚Äôt have an adjacency with a router that you are not neighbors with. Adjacent routers have exchanged Link state updates (LSU) and Database discirption packets (DBD) and are both on a full state with one another. OSPF routers on a broadcast network will only be fully adjacent to the DR and the BDR, the DR and the BDR have full adjacencies to all other routers. To find the adjacent routers, executeenableshow ip ospf neighborsThe need for Designated routers (DRs)OSPF routers forming adjacencies is great but that doesn‚Äôt scale well when we have 10, 20 or even 50 routers in a single subnet. say we had 7 routers, the formula to calculate the adjacencies is (n * (n - 1)) / 2, where n is the number of routers, that‚Äôs 21 adjacencies for just 7 routers, imagine 20, 30. That‚Äôs alot of overhead :( . In these scenarios where we have OSPF broadcast networks, we can elect a Designated router (DR) and a Backup designated router (BDR) incase the DR fails to be operational. All other routers now form adjacency with just the DR and the BDR instead of a full mesh of adjacencies. If a router now wants to send route updates to the DR and BDR, it uses the 224.0.0.6 ipv4 address and FF02::6 for ipv6.OSPF AreaIf you run OSPF in a simple network, the number of routers and links are relatively small, and best paths to all destinations are easily deduced. However, the information necessary to describe larger networks with many routers and links can become quite complex. SPF calculations that compare all possible paths for routes can easily turn into a complex and time-consuming calculation for the router. One of the main methods to reduce this complexity and the size of the link-state information database is to partition the OSPF routing domain into smaller units called areas, This also reduces the time it takes for the SPF algorithm to execute. All OSPF routers within an area must have identical entries within their respective LSDBs. Inside an area, routers exchange detailed link-state information. However, information transmitted from one area into another contains only summary details of the LSDB entries and not topology details about the originating area. These summary LSAs from another area are injected directly into the routing table and without making the router rerun its SPF algorithm.OSPF uses a two-layer area hierarchy: Backbone area, transit area or area 0 - Two principal requirements for the backbone area are that it must connect to all other nonbackbone areas and this area must be always contiguous; it is not allowed to have split up the backbone area. Generally, end users are not found within a backbone area. Nonbackbone area - The primary function of this area is to connect end users and resources. Nonbackbone areas are usually set up according to functional or geographic groupings. Traffic between different nonbackbone areas must always pass through the backbone area which is area 0. In the multi-area topology there are some special commonly used OSPF terms: ABR - This router has interfaces connected to at least two different OSPF areas, including the backbone area. ABRs contain LSDB information for each area, make route calculation for each area and advertise routing information between areas. ASBR - This router has at least one of its interfaces connected to an OSPF area and at least one of its interfaces connected to an external non-OSPF domain like a RIP AS (Autonomous System) or an EIGRP AS. OSPF states Down - This is the initial OSPF neighbor state. It means that no information (hello) have been received from a neighbor, but hello packets can be sent. Attempt - This state is only valid for manually configured neighbors in a Non-BroadcastMultiaccess (NBMA) environment, OSPF neighbors in this network type are manually configured because broadcasts and multicasts are not allowed and because OSPF uses multicast to discover neighbors, it wouldn‚Äôt find them unless neighbors are manually configured. The router sends unicast hello packets every poll interval to the neighbor from which hellos have not been received within the dead interval. INIT - At this stage, the router has recieved hello messages from its neighbors but the receiving router‚Äôs ID was not included in the hello message. 2-Way - At this stage, bi-directional communication has been established between two routers. This means that each router has seen the other routers‚Äô hello packet.This state is attained when the router receiving the hello packet sees its own Router ID within the received hello packet‚Äôs neighbor field. In this state, a router decides whether to become adjacent to this neighbor. On broadcast media and non-broadcast multiaccess (NBMA) networks, a router becomes fully adjacent only with the designated router (DR) and the backup designated router (BDR) and stays in the 2-way state with all other neighbors, these neighbors are refered to as DROther, The DR and the BDR is elected at the end of this state. On Point-to-Point and Point-to-Multipoint networks, a router becomes fully adjacent with all connected routers, there is no DR or BDR in these network types and no election takes place cause there is no DR, it just goes straight to full. Exstart - Once the DR and BDR are elected, the actual process of exchanging link state information can start between the routers and their DR and BDR. Exchange - In the exchange state, OSPF routers exchange database descriptor (DBD) packets. Database descriptors contain link-state advertisement (LSA) headers only and describe the contents of the entire link-state database. Routers also send link-state request packets and link-state update packets (which contain the entire LSA) in this state. The contents of the DBD received are compared to the information contained in the routers link-state database to check if new or more current link-state information is available with the neighbor. Loading - In this state, the actual exchange of link state information occurs. Based on the information provided by the DBDs, routers send link-state request packets. The neighbor then provides the requested link-state information in link-state update packets. During the adjacency, if a router receives an outdated or missing LSA, it requests that LSA by sending a link-state request packet. All link-state update packets are acknowledged. Full - In this state, routers are fully adjacent with each other. All the router and network LSAs are exchanged and the routers‚Äô databases are fully synchronized. The full state is the normal state for an OSPF router. If a router is stuck in another state, it is an indication that there are problems in forming adjacencies. If an OSPF router fails to receive hello messages after the time specified by the dead interval, the router goes back to the Down state. OSPF TimersThere are many timers associated with OSPF but the two main ones to understand are the hello timer and the dead interval. The hello timer controls how often a router sends hello messages to its neighbors to indicate its continued health. If a router doesn‚Äôt hear from its neighbor within the dead interval, the router drops its neighbor from the adjacency table because it assumes the neighbor is ‚Äúdead‚Äù and no longer reachable. while you can change the default hello and dead timers from their defaults which are 10 and 40 seconds respectively, you run the risk of having routers declaring their neighbors down too fast if you aggressively increase the hello timer more than the dead interval on the other side or generating more traffic on that link if you set the hello timers low.LSAs, LSUs, LSRs, LSAcks and the LSDBLSAs stand for Link state advertisements, this is the information exchanged between routers and it contains details about other networks. This information is used to build the LSDB (Link state database), a common misconception you‚Äôll see is ‚ÄúOSPF routers send LSA packets‚Äù, that‚Äôs not technically correct. LSAs are NOT packet types, instead they are the information contained in an LSU (Link state update).If a router attempts to construct its LSDB (Link state database) but its missing some information, it can request that missing information from other routers and that‚Äôs called a LSR (Link state request), if a neighbor sends an LSU containing the missing information, the router will send an acknowledgement is the form of a LSAck (Link state acknowledgement)Ok that was a ton üòÜ, i love OSPF, maybe it‚Äôs because it was the first dynamic routing protocol i‚Äôve learnt, it‚Äôs much more intelligent that RIP that‚Äôs for sure.I hope you enjoyed reading this.Take good care." }, { "title": "FHRPs - First Hop Redundancy Protocols", "url": "/posts/fhrp/", "categories": "Network Engineering, Network Redundancy", "tags": "cisco, ccna, hsrp, glbp, vrrp, networking", "date": "2022-05-04 00:00:00 +0300", "snippet": "FHRPs help us provide fault tolerance for our default gateways. if a client computer wants to get out of its local area network (LAN), it uses its default gateway to reach any other computers or serversoutside of its LAN. if the default gateway cannot be reached by the client, the client would simply not be able to reach other networks that reside outside of its LAN. Having a fault tolerant network will prove crucial to the continued functionality of a network. Default gateways on clientcomputers are usually statically configured by an administrator or dynamically learned from the DHCP server on the network. If a network has two default gateways, for example R1 and R2 a client can use, it wouldn‚Äôt help since they can only use one at a time and wouldn‚Äôt be able to fall back to the second gateway if the primary gateway fails to be operational, simply changing the default gateway on the host will fix the problem but that doesn‚Äôt scale very well in large environments. An FHRP protocol like HSRP, VRRP or GLBP will help us deploy a virtual IP (VIP) that both routers respond to and have it assigned as the default gateway for clients to use. Routers participating in the group will negotiate a protocol to support the VIP, in our case R1 and R2, so that they can respond to any incoming traffic destined to the VIP. Both routers will also negotiate who will respond to incoming traffic destined for the VIP, one router has to handle the virtual IP at any given point in time, say R2 takes the role, becomes the active router and Now R1 willbe on standby keeping track of R2 to see if its functional.now if R2 fails, the active role of managing the virtual router is handled by R1 and clients can send traffic through without downtime.To implement this, we have 2 Cisco proprietary protocols, namely, 1. HSRP (Hot Standby Router Protocol) 2. GLBP (Gateway Loadbalancing Protocol) and an Open standard calledVRRP (Virtual Router Redundancy Protocol).HSRPHSRP is a cisco proprietary protocol for establishing fault tolerant default gateways.It achieves this by allowing hosts to use a single router and maintain connectivity even if the actual first hop router fails to forward packets. multiple routers participate in this protocol and in turn create the illusion of one router. The router responsible for forwarding packets is known as the active router. A stanby router is chosen to replace the active router should it fail to be operational.configuring HSRP Note that all routers participating should be configured for HSRP Login to your router of choice using telnet, SSH or the console. Before executing any commands, its important to verify the interfaces you want to participate in HSRP and the network associated with the interface. The following configuration will be done based on our topology above.Carrying out router configuration over the network using Telnet is a security risk and NOT recommended. Click here to read more, use SSH instead.the picture below shows configuring HSRP on R2To verify HSRP has been deployed successfully, execute:show standbyin privilege exec mode as shown below.The show standby command reveals that the ‚Äúactive router is local‚Äù, this means that R2 is now responsible for incoming traffic destined for the virtual ip address at 10.16.0.3, it also means that R2 is the active router in the group.VRRPVRRP is an open standard supported by all routers that support FHRPs,VRRP uses terminologies like master and backup to represent the role of therouters participating in VRRP compared to HSRP that used ‚Äúactive‚Äù and ‚Äústandby‚Äù.In VRRP, the master is in charge of the virtual IP (VIP) and if it fails, the backuprouter will take over the role, When VRRP is enabled, an election happens betweenrouters to choose who will be master and backup, The router with the highestpriority will be selected as the master. The priority on the router interfaces is 100 by default, if priority is the same on all routers participating in VRRP (2 routers in our case), The router with the highest ip address will be chosen as the master. VRRP also haspreemption enabled by default, This means that if a new router that has better‚Äústuff‚Äù I.e higher priority steps in a VRRP group, it will take over the role of themaster regardless of if one was already in place, This is disabled by default inHSRP.This post will be updated to showcase VRRP configuration.GLBPGLBP stands for gateway load balancing protocol, This does exactly what thename says, it provides load balancing and fault tolerance between gateways,see‚Ä¶ Cisco Routers aren‚Äôt cheap by any means and buying one so that It can be onstandby or Backup isn‚Äôt ideal. The concept of fault tolerance is still the same inthat GLBP introduces a virtual IP (VIP) and if a router goes down, the second onewill step in to support the network, The benefit of using GLBP for fault tolerance isthat GLBP provides loadbalancing for the gateways, To achieve this, GLBPintroduces an AVG (Active virtual gateway) The AVG is supported by one of therouters and responds to ARP queries from clients that are looking for the mac address of their default gateway by the virtual mac addresses of the virtual routers in a round robin fashion. This means that clients on the Network will have different Mac addresses for the same gateway 10.16.0.3. packets destined for the default gateway at 10.16.0.3 will have different mac addresses and the switch will in turn forward them to two different destinations, in our case R1 and R2 and thats how we achieve load balance in our network.To configure GLBP‚Ä¶ Execute the following commands as shown below: Note that all routers participating should be configured for GLBP configuring R2‚Ä¶To verify that GLBP is working and successfully deployed, execute:show glpbin privilege Exec mode and parse the output returned.i hope you enjoyed reading this post as much as i enjoyed writing it. üòä" } ]
